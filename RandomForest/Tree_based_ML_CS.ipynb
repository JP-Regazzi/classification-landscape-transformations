{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUgKfuN4CXbk"
      },
      "source": [
        "2EL1730 Machine Learning Project - Jan. 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Up4s4ykEdcRL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "import seaborn as sb\n",
        "from datetime import date\n",
        "import geopandas as gpd\n",
        "import seaborn as sn\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, RocCurveDisplay\n",
        "from sklearn.metrics import recall_score, precision_score,accuracy_score, average_precision_score, f1_score, log_loss\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "import shap\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# General\n",
        "BASE_PATH = os.path.dirname(os.getcwd())\n",
        "COLORS = ['red', 'green', 'blue']\n",
        "METRICS = ['std', 'mean']\n",
        "GEOGRAPHY_TYPES = ['Dense Forest', 'Grass Land', 'Sparse Forest', 'Farms', 'River','Coastal', 'Lakes', 'Barren Land', 'Desert', 'Hills', 'Snow']\n",
        "URBAN_TYPES = ['Sparse Urban', 'Rural', 'Dense Urban', 'Urban Slum', 'Industrial']\n",
        "change_type_map = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,'Mega Projects': 5}\n",
        "\n",
        "CHANGE_STATUS_MAP = {None: 0, 'Greenland': 1, 'Land Cleared': 2, 'Materials Introduced': 3,\n",
        "                     'Prior Construction': 4, 'Excavation': 5, 'Construction Started': 6,\n",
        "                     'Construction Midway': 7, 'Materials Dumped': 8, 'Construction Done': 9,\n",
        "                     'Operational': 10}\n",
        "\n",
        "\n",
        "# Columns groups\n",
        "COLUMNS_TO_DROP = ['geography_type', 'urban_type', 'geometry', 'date0', 'date1', 'date2', 'date3', 'date4']\n",
        "DATE_COLUMNS = ['date0', 'date1', 'date2', 'date3', 'date4']\n",
        "\n",
        "# Output file\n",
        "OUTPUT_FILE = 'preprocessed_train.geojson'\n",
        "\n",
        "# Feature types\n",
        "BINARY_FEATURES = ['Dense Forest', 'Grass Land', 'Sparse Forest', 'Farms', 'River',\n",
        "                   'Coastal', 'Lakes', 'Barren Land', 'Desert', 'Hills', 'Snow',\n",
        "                   'Sparse Urban', 'Rural', 'Dense Urban', 'Urban Slum', 'Industrial']\n",
        "CATEGORICAL_FEATURES = ['change_status_date0', 'change_status_date1', 'change_status_date2', 'change_status_date3',\n",
        "                      'change_status_date4']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7Bk53c_dlzE",
        "outputId": "db58f386-faab-4e0d-df3e-f6b78b8dd8f0"
      },
      "outputs": [],
      "source": [
        "train_df = gpd.read_file(f'{BASE_PATH}/data/train.geojson', index_col=0)\n",
        "test_df = gpd.read_file(f'{BASE_PATH}/data/test.geojson', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT-PRIm12lEZ",
        "outputId": "54b0b499-5012-4a92-e133-59a40dced3ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
            "Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
            "Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
            "Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
            "Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n"
          ]
        }
      ],
      "source": [
        "train_df_pre_process = train_df.copy()\n",
        "\n",
        "# Fill missing data with 0\n",
        "train_df_pre_process = train_df_pre_process.fillna(0)\n",
        "\n",
        "# One-hot encoding for geography_type\n",
        "for geograph_type in GEOGRAPHY_TYPES:\n",
        "    train_df_pre_process[geograph_type] = train_df_pre_process['geography_type'].apply(lambda x: 1 if geograph_type in x else 0)\n",
        "\n",
        "for urban_type in URBAN_TYPES:\n",
        "    train_df_pre_process[urban_type] = train_df_pre_process['urban_type'].apply(lambda x: 1 if urban_type in x else 0)\n",
        "\n",
        "# Create new polygon features\n",
        "train_df_pre_process['area'] = train_df_pre_process['geometry'].area\n",
        "train_df_pre_process['length'] = train_df_pre_process['geometry'].length\n",
        "train_df_pre_process['centroid_x'] = train_df_pre_process['geometry'].centroid.x\n",
        "train_df_pre_process['centroid_y'] = train_df_pre_process['geometry'].centroid.y\n",
        "\n",
        "# Create new date related features\n",
        "train_df_pre_process[DATE_COLUMNS] = train_df_pre_process[DATE_COLUMNS].apply(pd.to_datetime)\n",
        "for metric in METRICS:\n",
        "    for color in COLORS:\n",
        "        for i in range(2, 6):\n",
        "            delta = train_df_pre_process[f'img_{color}_{metric}_date{i}'] - train_df_pre_process[f'img_{color}_{metric}_date{i-1}']\n",
        "            train_df_pre_process[f'img_{color}_{metric}_delta{i}'] = delta\n",
        "        train_df_pre_process[f'img_{color}_{metric}_delta_total'] = train_df_pre_process[f'img_{color}_{metric}_date5'] - train_df_pre_process[f'img_{color}_{metric}_date1']\n",
        "for i in range(1, 5):\n",
        "    train_df_pre_process[f'date_delta{i}'] = train_df_pre_process[f'date{i}'] - train_df_pre_process[f'date{i-1}']\n",
        "train_df_pre_process['date_delta_total'] = train_df_pre_process[f'date4'] - train_df_pre_process[f'date1']\n",
        "\n",
        "# Map change_type\n",
        "train_df_pre_process['change_type'] = train_df_pre_process['change_type'].map(change_type_map)\n",
        "for i in range(5): train_df_pre_process[f'change_status_date{i}'] = train_df_pre_process[f'change_status_date{i}'].map(CHANGE_STATUS_MAP)\n",
        "\n",
        "train_df_pre_process['date_delta_total'] = train_df_pre_process['date_delta_total']/np.timedelta64(1, 'D')\n",
        "train_df_pre_process['date_delta1'] = train_df_pre_process['date_delta1']/np.timedelta64(1, 'D')\n",
        "train_df_pre_process['date_delta2'] = train_df_pre_process['date_delta2']/np.timedelta64(1, 'D')\n",
        "train_df_pre_process['date_delta3'] = train_df_pre_process['date_delta3']/np.timedelta64(1, 'D')\n",
        "train_df_pre_process['date_delta4'] = train_df_pre_process['date_delta4']/np.timedelta64(1, 'D')\n",
        "\n",
        "# Drop uncessary columns\n",
        "train_df_pre_process = train_df_pre_process.drop(columns=COLUMNS_TO_DROP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Informations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ojHww7s4X6W",
        "outputId": "f2aec5b0-0d78-4787-9468-66ba4609b6ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 296146 entries, 0 to 296145\n",
            "Data columns (total 92 columns):\n",
            " #   Column                      Non-Null Count   Dtype  \n",
            "---  ------                      --------------   -----  \n",
            " 0   change_type                 296146 non-null  int64  \n",
            " 1   img_red_mean_date1          296146 non-null  float64\n",
            " 2   img_green_mean_date1        296146 non-null  float64\n",
            " 3   img_blue_mean_date1         296146 non-null  float64\n",
            " 4   img_red_std_date1           296146 non-null  float64\n",
            " 5   img_green_std_date1         296146 non-null  float64\n",
            " 6   img_blue_std_date1          296146 non-null  float64\n",
            " 7   img_red_mean_date2          296146 non-null  float64\n",
            " 8   img_green_mean_date2        296146 non-null  float64\n",
            " 9   img_blue_mean_date2         296146 non-null  float64\n",
            " 10  img_red_std_date2           296146 non-null  float64\n",
            " 11  img_green_std_date2         296146 non-null  float64\n",
            " 12  img_blue_std_date2          296146 non-null  float64\n",
            " 13  img_red_mean_date3          296146 non-null  float64\n",
            " 14  img_green_mean_date3        296146 non-null  float64\n",
            " 15  img_blue_mean_date3         296146 non-null  float64\n",
            " 16  img_red_std_date3           296146 non-null  float64\n",
            " 17  img_green_std_date3         296146 non-null  float64\n",
            " 18  img_blue_std_date3          296146 non-null  float64\n",
            " 19  img_red_mean_date4          296146 non-null  float64\n",
            " 20  img_green_mean_date4        296146 non-null  float64\n",
            " 21  img_blue_mean_date4         296146 non-null  float64\n",
            " 22  img_red_std_date4           296146 non-null  float64\n",
            " 23  img_green_std_date4         296146 non-null  float64\n",
            " 24  img_blue_std_date4          296146 non-null  float64\n",
            " 25  img_red_mean_date5          296146 non-null  float64\n",
            " 26  img_green_mean_date5        296146 non-null  float64\n",
            " 27  img_blue_mean_date5         296146 non-null  float64\n",
            " 28  img_red_std_date5           296146 non-null  float64\n",
            " 29  img_green_std_date5         296146 non-null  float64\n",
            " 30  img_blue_std_date5          296146 non-null  float64\n",
            " 31  change_status_date0         296146 non-null  float64\n",
            " 32  change_status_date1         296146 non-null  float64\n",
            " 33  change_status_date2         296146 non-null  float64\n",
            " 34  change_status_date3         296146 non-null  float64\n",
            " 35  change_status_date4         296146 non-null  float64\n",
            " 36  index                       296146 non-null  int64  \n",
            " 37  Dense Forest                296146 non-null  int64  \n",
            " 38  Grass Land                  296146 non-null  int64  \n",
            " 39  Sparse Forest               296146 non-null  int64  \n",
            " 40  Farms                       296146 non-null  int64  \n",
            " 41  River                       296146 non-null  int64  \n",
            " 42  Coastal                     296146 non-null  int64  \n",
            " 43  Lakes                       296146 non-null  int64  \n",
            " 44  Barren Land                 296146 non-null  int64  \n",
            " 45  Desert                      296146 non-null  int64  \n",
            " 46  Hills                       296146 non-null  int64  \n",
            " 47  Snow                        296146 non-null  int64  \n",
            " 48  Sparse Urban                296146 non-null  int64  \n",
            " 49  Rural                       296146 non-null  int64  \n",
            " 50  Dense Urban                 296146 non-null  int64  \n",
            " 51  Urban Slum                  296146 non-null  int64  \n",
            " 52  Industrial                  296146 non-null  int64  \n",
            " 53  area                        296146 non-null  float64\n",
            " 54  length                      296146 non-null  float64\n",
            " 55  centroid_x                  296146 non-null  float64\n",
            " 56  centroid_y                  296146 non-null  float64\n",
            " 57  img_red_std_delta2          296146 non-null  float64\n",
            " 58  img_red_std_delta3          296146 non-null  float64\n",
            " 59  img_red_std_delta4          296146 non-null  float64\n",
            " 60  img_red_std_delta5          296146 non-null  float64\n",
            " 61  img_red_std_delta_total     296146 non-null  float64\n",
            " 62  img_green_std_delta2        296146 non-null  float64\n",
            " 63  img_green_std_delta3        296146 non-null  float64\n",
            " 64  img_green_std_delta4        296146 non-null  float64\n",
            " 65  img_green_std_delta5        296146 non-null  float64\n",
            " 66  img_green_std_delta_total   296146 non-null  float64\n",
            " 67  img_blue_std_delta2         296146 non-null  float64\n",
            " 68  img_blue_std_delta3         296146 non-null  float64\n",
            " 69  img_blue_std_delta4         296146 non-null  float64\n",
            " 70  img_blue_std_delta5         296146 non-null  float64\n",
            " 71  img_blue_std_delta_total    296146 non-null  float64\n",
            " 72  img_red_mean_delta2         296146 non-null  float64\n",
            " 73  img_red_mean_delta3         296146 non-null  float64\n",
            " 74  img_red_mean_delta4         296146 non-null  float64\n",
            " 75  img_red_mean_delta5         296146 non-null  float64\n",
            " 76  img_red_mean_delta_total    296146 non-null  float64\n",
            " 77  img_green_mean_delta2       296146 non-null  float64\n",
            " 78  img_green_mean_delta3       296146 non-null  float64\n",
            " 79  img_green_mean_delta4       296146 non-null  float64\n",
            " 80  img_green_mean_delta5       296146 non-null  float64\n",
            " 81  img_green_mean_delta_total  296146 non-null  float64\n",
            " 82  img_blue_mean_delta2        296146 non-null  float64\n",
            " 83  img_blue_mean_delta3        296146 non-null  float64\n",
            " 84  img_blue_mean_delta4        296146 non-null  float64\n",
            " 85  img_blue_mean_delta5        296146 non-null  float64\n",
            " 86  img_blue_mean_delta_total   296146 non-null  float64\n",
            " 87  date_delta1                 296146 non-null  float64\n",
            " 88  date_delta2                 296146 non-null  float64\n",
            " 89  date_delta3                 296146 non-null  float64\n",
            " 90  date_delta4                 296146 non-null  float64\n",
            " 91  date_delta_total            296146 non-null  float64\n",
            "dtypes: float64(74), int64(18)\n",
            "memory usage: 207.9 MB\n"
          ]
        }
      ],
      "source": [
        "# Fill missing data with 0\n",
        "train_df_pre_process = train_df_pre_process.fillna(0)\n",
        "train_df_pre_process.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Standardization of numeric features and splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UNifXLj74Sxz"
      },
      "outputs": [],
      "source": [
        "# Creating X and y\n",
        "X = np.array(train_df_pre_process.drop('change_type', axis=1))\n",
        "y = np.array(train_df_pre_process['change_type'])\n",
        "\n",
        "#enn = EditedNearestNeighbours(kind_sel=\"all\")\n",
        "#X, y = enn.fit_resample(X, y) #undersampling\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Indices of numeric and categorical columns\n",
        "numeric_features = [i for i in range(X.shape[1]) if train_df_pre_process.drop(columns = ['change_type']).columns[i] not in BINARY_FEATURES + CATEGORICAL_FEATURES]\n",
        "\n",
        "# Create the transformer\n",
        "preprocessor = ColumnTransformer(transformers=[('num', StandardScaler(), numeric_features),])\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_scaled = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data\n",
        "X_test_scaled = preprocessor.transform(X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data preprocessing of test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDRHL6ik4sdW",
        "outputId": "a40a83ee-b723-4acb-db83-eb34a60c9c62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
            "Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
            "Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
            "Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
            "Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n"
          ]
        }
      ],
      "source": [
        "test_df_pre_process = test_df.copy()\n",
        "\n",
        "# Fill missing data with 0\n",
        "test_df_pre_process = test_df_pre_process.fillna(0)\n",
        "\n",
        "# One-hot encoding for geography_type\n",
        "for geograph_type in GEOGRAPHY_TYPES:\n",
        "    test_df_pre_process[geograph_type] = test_df_pre_process['geography_type'].apply(lambda x: 1 if geograph_type in x else 0)\n",
        "\n",
        "for urban_type in URBAN_TYPES:\n",
        "    test_df_pre_process[urban_type] = test_df_pre_process['urban_type'].apply(lambda x: 1 if urban_type in x else 0)\n",
        "\n",
        "# Create new polygon features\n",
        "test_df_pre_process['area'] = test_df_pre_process['geometry'].area\n",
        "test_df_pre_process['length'] = test_df_pre_process['geometry'].length\n",
        "test_df_pre_process['centroid_x'] = test_df_pre_process['geometry'].centroid.x\n",
        "test_df_pre_process['centroid_y'] = test_df_pre_process['geometry'].centroid.y\n",
        "\n",
        "# Create new date related features\n",
        "test_df_pre_process[DATE_COLUMNS] = test_df_pre_process[DATE_COLUMNS].apply(pd.to_datetime)\n",
        "for metric in METRICS:\n",
        "    for color in COLORS:\n",
        "        for i in range(2, 6):\n",
        "            delta = test_df_pre_process[f'img_{color}_{metric}_date{i}'] - test_df_pre_process[f'img_{color}_{metric}_date{i-1}']\n",
        "            test_df_pre_process[f'img_{color}_{metric}_delta{i}'] = delta\n",
        "        test_df_pre_process[f'img_{color}_{metric}_delta_total'] = test_df_pre_process[f'img_{color}_{metric}_date5'] - test_df_pre_process[f'img_{color}_{metric}_date1']\n",
        "for i in range(1, 5):\n",
        "    test_df_pre_process[f'date_delta{i}'] = test_df_pre_process[f'date{i}'] - test_df_pre_process[f'date{i-1}']\n",
        "test_df_pre_process['date_delta_total'] = test_df_pre_process[f'date4'] - test_df_pre_process[f'date1']\n",
        "\n",
        "for i in range(5): test_df_pre_process[f'change_status_date{i}'] = test_df_pre_process[f'change_status_date{i}'].map(CHANGE_STATUS_MAP)\n",
        "\n",
        "test_df_pre_process['date_delta_total'] = test_df_pre_process['date_delta_total']/np.timedelta64(1, 'D')\n",
        "test_df_pre_process['date_delta1'] = test_df_pre_process['date_delta1']/np.timedelta64(1, 'D')\n",
        "test_df_pre_process['date_delta2'] = test_df_pre_process['date_delta2']/np.timedelta64(1, 'D')\n",
        "test_df_pre_process['date_delta3'] = test_df_pre_process['date_delta3']/np.timedelta64(1, 'D')\n",
        "test_df_pre_process['date_delta4'] = test_df_pre_process['date_delta4']/np.timedelta64(1, 'D')\n",
        "\n",
        "# Drop uncessary columns\n",
        "test_df_pre_process = test_df_pre_process.drop(columns=COLUMNS_TO_DROP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYlDoj9ffI48",
        "outputId": "9f48e7a0-4d98-4975-f549-4c66a672040b"
      },
      "outputs": [],
      "source": [
        "test_df_pre_process = test_df_pre_process.fillna(0)\n",
        "\n",
        "numeric_features = [col for col in test_df_pre_process.columns if col not in BINARY_FEATURES + CATEGORICAL_FEATURES]\n",
        "for col_name in numeric_features:\n",
        "    mean_value = test_df_pre_process[col_name].mean()\n",
        "    std_value = test_df_pre_process[col_name].std()\n",
        "    test_df_pre_process[col_name] = (test_df_pre_process[col_name] - mean_value) / std_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOj94oM5474B",
        "outputId": "08b444bd-fa39-4158-854f-d49f942f3ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({2: 148435, 3: 100422, 0: 31509, 1: 14305, 4: 1324, 5: 151})\n"
          ]
        }
      ],
      "source": [
        "print(Counter(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forest - without feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeJb4kfUmjJ7",
        "outputId": "019eec02-c283-42a8-bcf0-e4c82508e6ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.76      0.76      6345\n",
            "           1       0.87      0.48      0.61      2806\n",
            "           2       0.78      0.80      0.79     29776\n",
            "           3       0.67      0.69      0.68     19999\n",
            "           4       0.67      0.01      0.01       281\n",
            "           5       0.00      0.00      0.00        23\n",
            "\n",
            "    accuracy                           0.74     59230\n",
            "   macro avg       0.62      0.46      0.48     59230\n",
            "weighted avg       0.74      0.74      0.74     59230\n",
            "\n",
            "Model F1-score on validation data: 0.7373963468212685\n"
          ]
        }
      ],
      "source": [
        "#test data\n",
        "X_test = np.array(test_df_pre_process)\n",
        "\n",
        "clf = RandomForestClassifier(bootstrap = True, max_depth= 40, min_samples_leaf= 1, min_samples_split= 3, n_estimators= 100)\n",
        "\n",
        "# Train the model\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation data\n",
        "y_pred = clf.predict(X_val)\n",
        "\n",
        "test_accuracy = clf.score(X_val, y_val)\n",
        "\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "# Calculate and print the F1-score\n",
        "f1 = f1_score(y_val, y_pred , average='weighted')\n",
        "print(f'Model F1-score on validation data: {f1}')\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_test = clf.predict(X_test)\n",
        "\n",
        "## Save results to submission file\n",
        "pred_df = pd.DataFrame(y_pred_test, columns=['change_type'])\n",
        "#pred_df_LR.to_csv(\"LR_submission.csv\", index=True, index_label='Id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forest - with feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "wkbDiviEduZl",
        "outputId": "f73fcb8a-a6cb-4760-a9d5-27efbbd9a73a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.80      0.79      6345\n",
            "           1       0.85      0.53      0.65      2806\n",
            "           2       0.79      0.80      0.80     29776\n",
            "           3       0.68      0.70      0.69     19999\n",
            "           4       0.57      0.01      0.03       281\n",
            "           5       0.00      0.00      0.00        23\n",
            "\n",
            "    accuracy                           0.75     59230\n",
            "   macro avg       0.61      0.47      0.49     59230\n",
            "weighted avg       0.75      0.75      0.75     59230\n",
            "\n",
            "Model F1-score on validation data: 0.748347481796586\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nscore = cross_val_score(lr, X_train_selected, y_train, scoring='f1', cv=10)\\nprint('CV F1-score: %.3f +/- %.3f' % (np.mean(score), np.std(score)))\\n\\n# Get features\\nprint(select.get_support(indices=True))\\n\""
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#test data\n",
        "X_test = np.array(test_df_pre_process)\n",
        "\n",
        "#Embedded methods to feature selection\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators= 100, random_state=10), threshold='median')\n",
        "sel.fit(X_train, y_train)\n",
        "\n",
        "X_train_selected = sel.transform(X_train)\n",
        "X_val_selected = sel.transform(X_val)\n",
        "X_test_selected = sel.transform(X_test)\n",
        "\n",
        "clf = RandomForestClassifier(bootstrap = True, max_depth= 40, min_samples_leaf= 1, min_samples_split= 3, n_estimators= 100)\n",
        "clf.fit(X_train_selected, y_train)\n",
        "\n",
        "# Make predictions on the validation data\n",
        "y_pred = clf.predict(X_val_selected)\n",
        "\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "# Calculate and print the F1-score\n",
        "f1 = f1_score(y_val, y_pred , average='weighted')\n",
        "print(f'Model F1-score on validation data: {f1}')\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_test = clf.predict(X_test_selected)\n",
        "\n",
        "## Save results to submission file\n",
        "pred_df = pd.DataFrame(y_pred_test, columns=['change_type'])\n",
        "#pred_df_LR.to_csv(\"LR_submission.csv\", index=True, index_label='Id')\n",
        "\n",
        "'''\n",
        "score = cross_val_score(lr, X_train_selected, y_train, scoring='f1', cv=10)\n",
        "print('CV F1-score: %.3f +/- %.3f' % (np.mean(score), np.std(score)))\n",
        "\n",
        "# Get features\n",
        "print(select.get_support(indices=True))\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Xgboost - without feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsBJ9TC_pUbc",
        "outputId": "71c465bc-b0b1-45d8-9ff2-945be11cba7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.89      0.83      6345\n",
            "           1       0.81      0.68      0.74      2806\n",
            "           2       0.79      0.80      0.80     29776\n",
            "           3       0.70      0.68      0.69     19999\n",
            "           4       0.50      0.03      0.06       281\n",
            "           5       0.00      0.00      0.00        23\n",
            "\n",
            "    accuracy                           0.76     59230\n",
            "   macro avg       0.60      0.51      0.52     59230\n",
            "weighted avg       0.76      0.76      0.76     59230\n",
            "\n",
            "Model F1-score on validation data: 0.7568684544208875\n"
          ]
        }
      ],
      "source": [
        "#test data\n",
        "X_test = np.array(test_df_pre_process)\n",
        "\n",
        "clf = xgb.XGBClassifier(n_estimators = 150, subsample = 0.99, learning_rate=0.2,colsample_bytree=1, random_state=137)\n",
        "\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_val)\n",
        "\n",
        "test_accuracy = clf.score(X_val, y_val)\n",
        "\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "# Calculate and print the F1-score\n",
        "f1 = f1_score(y_val, y_pred , average='weighted')\n",
        "print(f'Model F1-score on validation data: {f1}')\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_test = clf.predict(X_test)\n",
        "\n",
        "## Save results to submission file\n",
        "pred_df = pd.DataFrame(y_pred_test, columns=['change_type'])\n",
        "#pred_df.to_csv(\"Xgboost_submission.csv\", index=True, index_label='Id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Xgboost - with feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Kv25Qjyd9Dd",
        "outputId": "f6d1f894-05d5-4d1f-a937-4ab0c2563ef8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.89      0.83      6345\n",
            "           1       0.78      0.57      0.66      2806\n",
            "           2       0.79      0.80      0.79     29776\n",
            "           3       0.69      0.67      0.68     19999\n",
            "           4       0.43      0.04      0.07       281\n",
            "           5       0.00      0.00      0.00        23\n",
            "\n",
            "    accuracy                           0.75     59230\n",
            "   macro avg       0.58      0.50      0.50     59230\n",
            "weighted avg       0.75      0.75      0.75     59230\n",
            "\n",
            "Model F1-score on validation data: 0.7489683871544114\n"
          ]
        }
      ],
      "source": [
        "#Embedded methods to feature selection\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators= 100, random_state=10), threshold='median')\n",
        "\n",
        "# Train the model\n",
        "sel.fit(X_train, y_train)\n",
        "X_train_selected = sel.transform(X_train)\n",
        "X_val_selected = sel.transform(X_val)\n",
        "X_test_selected = sel.transform(X_test)\n",
        "\n",
        "clf = xgb.XGBClassifier(n_estimators = 150, subsample = 0.99, learning_rate=0.2,colsample_bytree=1, random_state=137)\n",
        "clf.fit(X_train_selected, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_val_selected)\n",
        "\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "# Calculate and print the F1-score\n",
        "f1 = f1_score(y_val, y_pred , average='weighted')\n",
        "print(f'Model F1-score on validation data: {f1}')\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_test = clf.predict(X_test_selected)\n",
        "\n",
        "## Save results to submission file\n",
        "pred_df = pd.DataFrame(y_pred_test, columns=['change_type'])\n",
        "#pred_df.to_csv(\"Xgboost_submission.csv\", index=True, index_label='Id')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
