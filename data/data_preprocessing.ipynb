{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "BASE_PATH = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Mapping\n",
    "CHANGE_TYPE_MAP = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "       'Mega Projects': 5}\n",
    "CHANGE_STATUS_MAP = {'Greenland': 0, 'Land Cleared': 1, 'Excavation': 1, 'Materials Dumped': 3, 'Prior Construction': 3, 'Materials Introduced': 4, 'Construction Started': 5, 'Construction Midway': 6, 'Construction Done': 8, 'Operational': 10, None: None}\n",
    "\n",
    "# Data\n",
    "COLORS = ['red', 'green', 'blue']\n",
    "METRICS = ['std', 'mean']\n",
    "GEOGRAPHY_TYPES = ['Dense Forest', 'Grass Land', 'Sparse Forest', 'Farms', 'River',\n",
    "                   'Coastal', 'Lakes', 'Barren Land', 'Desert', 'Hills', 'Snow'] \n",
    "URBAN_TYPES = ['Sparse Urban', 'Rural', 'Dense Urban', 'Urban Slum', 'Industrial']\n",
    "\n",
    "# Columns groups\n",
    "COLUMNS_TO_DROP = ['geography_type', 'urban_type']\n",
    "DATE_COLUMNS = ['date0', 'date1', 'date2', 'date3', 'date4']\n",
    "CHANGE_STATUS_COLUMNS = ['change_status_date0', 'change_status_date1', 'change_status_date2', 'change_status_date3', 'change_status_date4']\n",
    "CHANGE_STATUS_VALUE_COLUMNS = ['change_status_value_date0', 'change_status_value_date1', 'change_status_value_date2', 'change_status_value_date3', 'change_status_value_date4']\n",
    "\n",
    "# Output file\n",
    "OUTPUT_FILE = 'preprocessed_train.geojson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read data\n",
    "train_df = gpd.read_file(f'{BASE_PATH}/data/train.geojson', index_col=0)\n",
    "#test_df = gpd.read_file(f'{BASE_PATH}/data/test.geojson', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-hot encoding\n",
    "for geograph_type in GEOGRAPHY_TYPES:\n",
    "    train_df[geograph_type] = train_df['geography_type'].apply(lambda x: 1 if geograph_type in x else 0)\n",
    "for urban_type in URBAN_TYPES:\n",
    "    train_df[urban_type] = train_df['urban_type'].apply(lambda x: 1 if urban_type in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171771/3199303419.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  train_df['area'] = train_df['geometry'].area\n",
      "/tmp/ipykernel_171771/3199303419.py:3: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  train_df['length'] = train_df['geometry'].length\n",
      "/tmp/ipykernel_171771/3199303419.py:4: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  train_df['centroid'] = train_df['geometry'].centroid\n"
     ]
    }
   ],
   "source": [
    "## Create new polygon features\n",
    "train_df['area'] = train_df['geometry'].area\n",
    "train_df['length'] = train_df['geometry'].length\n",
    "train_df['centroid'] = train_df['geometry'].centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix date\n",
    "train_df[DATE_COLUMNS] = train_df[DATE_COLUMNS].apply(lambda x: pd.to_datetime(x, format='%d-%m-%Y', errors='coerce'))\n",
    "\n",
    "## Create deltas: color and time\n",
    "for metric in METRICS:\n",
    "    for color in COLORS:\n",
    "        for i in range(2, 6):\n",
    "            delta = train_df[f'img_{color}_{metric}_date{i}'] - train_df[f'img_{color}_{metric}_date{i-1}']\n",
    "            train_df[f'img_{color}_{metric}_delta{i}'] = delta\n",
    "        train_df[f'img_{color}_{metric}_delta_total'] = train_df[f'img_{color}_{metric}_date5'] - train_df[f'img_{color}_{metric}_date1']\n",
    "for i in range(1, 5):\n",
    "    train_df[f'date_delta{i}'] = train_df[f'date{i}'] - train_df[f'date{i-1}']\n",
    "train_df['date_delta_total'] = train_df[f'date4'] - train_df[f'date1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map change_type\n",
    "train_df['change_type'] = train_df['change_type'].map(CHANGE_TYPE_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171771/3193938916.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df[CHANGE_STATUS_VALUE_COLUMNS] = train_df[CHANGE_STATUS_COLUMNS].replace(CHANGE_STATUS_MAP)\n"
     ]
    }
   ],
   "source": [
    "## Create change_status_values\n",
    "train_df[CHANGE_STATUS_VALUE_COLUMNS] = train_df[CHANGE_STATUS_COLUMNS].replace(CHANGE_STATUS_MAP)\n",
    "\n",
    "## Create civilization_rate\n",
    "num_samples = train_df.shape[0]\n",
    "coef = np.zeros((num_samples))\n",
    "time_ctt = 1e9*60*90*24\n",
    "ones = np.ones((num_samples,5,1))\n",
    "\n",
    "Y = np.array(train_df[CHANGE_STATUS_VALUE_COLUMNS].astype(float))\n",
    "Y_nan_mask = np.isnan(Y)\n",
    "X = np.array(train_df[DATE_COLUMNS].astype(int))[:,:,np.newaxis]/time_ctt\n",
    "X = np.dstack((ones,X))\n",
    "X[Y_nan_mask,:] = 0\n",
    "Y[Y_nan_mask] = 0\n",
    "\n",
    "eye = np.eye(2)*0.0001\n",
    "for i in range(num_samples):\n",
    "    x = X[i].reshape((5,2))\n",
    "    y = Y[i].reshape((5))\n",
    "    coef[i] = (np.linalg.inv(eye+x.T@x)@x.T@y)[1]\n",
    "    #print(y, train_df[\"change_type\"].iloc[i])\n",
    "train_df[\"civilizating_rate\"] = coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop uncessary columns\n",
    "train_df = train_df.drop(columns=COLUMNS_TO_DROP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GeoDataFrame contains multiple geometry columns but GeoDataFrame.to_file supports only a single geometry column. Use a GeoDataFrame.to_parquet or GeoDataFrame.to_feather, drop additional geometry columns or convert them to a supported format like a well-known text (WKT) using `GeoSeries.to_wkt()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/rick/Dropbox/disciplininhas/SG6/ML/machine-learning-cs/data/data_preprocessing.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rick/Dropbox/disciplininhas/SG6/ML/machine-learning-cs/data/data_preprocessing.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## Save output file\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rick/Dropbox/disciplininhas/SG6/ML/machine-learning-cs/data/data_preprocessing.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_df\u001b[39m.\u001b[39mset_geometry(\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rick/Dropbox/disciplininhas/SG6/ML/machine-learning-cs/data/data_preprocessing.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_df\u001b[39m.\u001b[39;49mto_file(OUTPUT_FILE)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/geopandas/geodataframe.py:1246\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[0;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \n\u001b[1;32m   1157\u001b[0m \u001b[39mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \n\u001b[1;32m   1243\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgeopandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfile\u001b[39;00m \u001b[39mimport\u001b[39;00m _to_file\n\u001b[0;32m-> 1246\u001b[0m _to_file(\u001b[39mself\u001b[39;49m, filename, driver, schema, index, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/geopandas/io/file.py:621\u001b[0m, in \u001b[0;36m_to_file\u001b[0;34m(df, filename, driver, schema, index, mode, crs, engine, **kwargs)\u001b[0m\n\u001b[1;32m    614\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    615\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mColumn names longer than 10 characters will be truncated when saved to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    616\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mESRI Shapefile.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    617\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    620\u001b[0m \u001b[39mif\u001b[39;00m (df\u001b[39m.\u001b[39mdtypes \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 621\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    622\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGeoDataFrame contains multiple geometry columns but GeoDataFrame.to_file \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    623\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupports only a single geometry column. Use a GeoDataFrame.to_parquet or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    624\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGeoDataFrame.to_feather, drop additional geometry columns or convert them \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    625\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto a supported format like a well-known text (WKT) using \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    626\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`GeoSeries.to_wkt()`.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    627\u001b[0m     )\n\u001b[1;32m    629\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    630\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m should be one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: GeoDataFrame contains multiple geometry columns but GeoDataFrame.to_file supports only a single geometry column. Use a GeoDataFrame.to_parquet or GeoDataFrame.to_feather, drop additional geometry columns or convert them to a supported format like a well-known text (WKT) using `GeoSeries.to_wkt()`."
     ]
    }
   ],
   "source": [
    "## Save output file\n",
    "#train_df.set_geometry('geometry')\n",
    "#train_df.to_file(OUTPUT_FILE) ##TA DANDO ERRO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
