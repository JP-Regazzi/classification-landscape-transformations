{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "BASE_PATH = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Mapping\n",
    "CHANGE_TYPE_MAP = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "       'Mega Projects': 5}\n",
    "CHANGE_STATUS_MAP = {'Greenland': 0, 'Land Cleared': 1, 'Excavation': 1, 'Materials Dumped': 3, 'Prior Construction': 3, 'Materials Introduced': 4, 'Construction Started': 5, 'Construction Midway': 6, 'Construction Done': 8, 'Operational': 10, None: None}\n",
    "\n",
    "# Data\n",
    "COLORS = ['red', 'green', 'blue']\n",
    "METRICS = ['std', 'mean']\n",
    "GEOGRAPHY_TYPES = ['Dense Forest', 'Grass Land', 'Sparse Forest', 'Farms', 'River',\n",
    "                   'Coastal', 'Lakes', 'Barren Land', 'Desert', 'Hills', 'Snow'] \n",
    "URBAN_TYPES = ['Sparse Urban', 'Rural', 'Dense Urban', 'Urban Slum', 'Industrial']\n",
    "\n",
    "# Columns groups\n",
    "COLUMNS_TO_DROP = ['geography_type', 'urban_type']\n",
    "DATE_COLUMNS = ['date0', 'date1', 'date2', 'date3', 'date4']\n",
    "CHANGE_STATUS_COLUMNS = ['change_status_date0', 'change_status_date1', 'change_status_date2', 'change_status_date3', 'change_status_date4']\n",
    "CHANGE_STATUS_VALUE_COLUMNS = ['change_status_value_date0', 'change_status_value_date1', 'change_status_value_date2', 'change_status_value_date3', 'change_status_value_date4']\n",
    "\n",
    "# Output file\n",
    "OUTPUT_FILE = 'preprocessed_train.geojson'\n",
    "\n",
    "# Safety\n",
    "MAPPED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read data\n",
    "train_df = gpd.read_file(f'{BASE_PATH}/data/train.geojson', index_col=0)\n",
    "#test_df = gpd.read_file(f'{BASE_PATH}/data/test.geojson', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-hot encoding\n",
    "for geograph_type in GEOGRAPHY_TYPES:\n",
    "    train_df[geograph_type] = train_df['geography_type'].apply(lambda x: 1 if geograph_type in x else 0)\n",
    "for urban_type in URBAN_TYPES:\n",
    "    train_df[urban_type] = train_df['urban_type'].apply(lambda x: 1 if urban_type in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_214543/3380409933.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  train_df['area'] = train_df['geometry'].area\n",
      "/tmp/ipykernel_214543/3380409933.py:3: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  train_df['length'] = train_df['geometry'].length\n",
      "/tmp/ipykernel_214543/3380409933.py:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  train_df['centroid_x'] = train_df['geometry'].centroid.x\n",
      "/tmp/ipykernel_214543/3380409933.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  train_df['centroid_y'] = train_df['geometry'].centroid.y\n"
     ]
    }
   ],
   "source": [
    "## Create new polygon features\n",
    "train_df['area'] = train_df['geometry'].area\n",
    "train_df['length'] = train_df['geometry'].length\n",
    "train_df['area_to_length_ratio'] = train_df['area'] / train_df['length'] # the more, the closer to square\n",
    "train_df['centroid_x'] = train_df['geometry'].centroid.x\n",
    "train_df['centroid_y'] = train_df['geometry'].centroid.y\n",
    "bounds = train_df['geometry'].bounds\n",
    "train_df['angle'] = np.arctan((bounds['maxy']-bounds['miny'])/(bounds['maxx']-bounds['minx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert date from string to date\n",
    "train_df[DATE_COLUMNS] = train_df[DATE_COLUMNS].apply(lambda x: pd.to_datetime(x, format='%d-%m-%Y', errors='coerce'))\n",
    "\n",
    "## Create deltas color[std, mean] \n",
    "for metric in METRICS:\n",
    "    for color in COLORS:\n",
    "        for i in range(2, 6):\n",
    "            delta = train_df[f'img_{color}_{metric}_date{i}'] - train_df[f'img_{color}_{metric}_date{i-1}']\n",
    "            train_df[f'img_{color}_{metric}_delta{i}'] = delta\n",
    "        train_df[f'img_{color}_{metric}_delta_total'] = train_df[f'img_{color}_{metric}_date5'] - train_df[f'img_{color}_{metric}_date1']\n",
    "\n",
    "## Create deltas time \n",
    "for i in range(1, 5):\n",
    "    train_df[f'date_delta{i}'] = train_df[f'date{i}'] - train_df[f'date{i-1}']\n",
    "train_df['date_delta_total'] = train_df[f'date4'] - train_df[f'date0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardizing colors mean by the proportion\n",
    "for i in range(1, 6):\n",
    "    color_sum = train_df[f'img_blue_mean_date{i}'] + train_df[f'img_green_mean_date{i}'] + train_df[f'img_red_mean_date{i}']\n",
    "    for color in COLORS:\n",
    "        train_df[f'img_{color}_mean_prop_date{i}'] = train_df[f'img_{color}_mean_date{i}']/color_sum\n",
    "\n",
    "## Create img_{color}_mean_prop_rate\n",
    "num_samples = train_df.shape[0]\n",
    "ones = np.ones((num_samples,5,1))\n",
    "\n",
    "for color in COLORS:\n",
    "    coef = np.zeros((num_samples))\n",
    "    COLOR_MEAN_COLUMNS = [f'img_{color}_mean_prop_date{i}' for i in range (1,6)]\n",
    "    \n",
    "    Y = np.array(train_df[COLOR_MEAN_COLUMNS].astype(float))\n",
    "    X = np.array(train_df[DATE_COLUMNS].astype(int))[:,:,np.newaxis]\n",
    "    X = np.dstack((ones,X))\n",
    "    nan_mask = np.isnan(Y) | np.isnan(X[:,:,1])\n",
    "    X[nan_mask,:] = 0\n",
    "    Y[nan_mask] = 0\n",
    "\n",
    "    eye = np.eye(2)*0.0001\n",
    "    for i in range(num_samples):\n",
    "        x = X[i].reshape((5,2))\n",
    "        y = Y[i].reshape((5))\n",
    "        coef[i] = (np.linalg.inv(eye+x.T@x)@x.T@y)[1]\n",
    "        \n",
    "    train_df[f'img_{color}_mean_prop_rate'] = coef\n",
    "    \n",
    "## Create img_{color}_std_rate\n",
    "for color in COLORS:\n",
    "    coef = np.zeros((num_samples))\n",
    "    COLOR_STD_COLUMNS = [f'img_{color}_std_date{i}' for i in range (1,6)]\n",
    "    \n",
    "    Y = np.array(train_df[COLOR_STD_COLUMNS].astype(float))\n",
    "    X = np.array(train_df[DATE_COLUMNS].astype(int))[:,:,np.newaxis]\n",
    "    X = np.dstack((ones,X))\n",
    "    nan_mask = np.isnan(Y) | np.isnan(X[:,:,1])\n",
    "    X[nan_mask,:] = 0\n",
    "    Y[nan_mask] = 0\n",
    "\n",
    "    eye = np.eye(2)*0.0001\n",
    "    for i in range(num_samples):\n",
    "        x = X[i].reshape((5,2))\n",
    "        y = Y[i].reshape((5))\n",
    "        coef[i] = (np.linalg.inv(eye+x.T@x)@x.T@y)[1]\n",
    "        \n",
    "    train_df[f'img_{color}_std_rate'] = coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map change_type\n",
    "if ~MAPPED:\n",
    "    train_df['change_type'] = train_df['change_type'].map(CHANGE_TYPE_MAP)\n",
    "    MAPPED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_214543/3193938916.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df[CHANGE_STATUS_VALUE_COLUMNS] = train_df[CHANGE_STATUS_COLUMNS].replace(CHANGE_STATUS_MAP)\n"
     ]
    }
   ],
   "source": [
    "## Create change_status_values\n",
    "train_df[CHANGE_STATUS_VALUE_COLUMNS] = train_df[CHANGE_STATUS_COLUMNS].replace(CHANGE_STATUS_MAP)\n",
    "\n",
    "## Create civilization_rate\n",
    "num_samples = train_df.shape[0]\n",
    "coef = np.zeros((num_samples))\n",
    "time_ctt = 1e9*60*90*24\n",
    "ones = np.ones((num_samples,5,1))\n",
    "\n",
    "Y = np.array(train_df[CHANGE_STATUS_VALUE_COLUMNS].astype(float))\n",
    "Y_nan_mask = np.isnan(Y)\n",
    "X = np.array(train_df[DATE_COLUMNS].astype(int))[:,:,np.newaxis]/time_ctt\n",
    "X = np.dstack((ones,X))\n",
    "X[Y_nan_mask,:] = 0\n",
    "Y[Y_nan_mask] = 0\n",
    "\n",
    "eye = np.eye(2)*0.0001\n",
    "for i in range(num_samples):\n",
    "    x = X[i].reshape((5,2))\n",
    "    y = Y[i].reshape((5))\n",
    "    coef[i] = (np.linalg.inv(eye+x.T@x)@x.T@y)[1]\n",
    "    #print(y, train_df[\"change_type\"].iloc[i])\n",
    "train_df[\"civilizating_rate\"] = coef\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalization and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop uncessary columns\n",
    "train_df = train_df.drop(columns=COLUMNS_TO_DROP)\n",
    "train_df = train_df.drop(columns=CHANGE_STATUS_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANOVA for each feature\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Assuming 'change_type' is the column name for classification effects\n",
    "change_type_column = 'change_type'\n",
    "\n",
    "# Group the data by 'change_type'\n",
    "grouped_data = train_df.groupby(change_type_column)\n",
    "\n",
    "# List to store F-values\n",
    "f_values = []\n",
    "\n",
    "# Loop through each feature (column) and calculate F-value\n",
    "for feature_column in train_df.columns:\n",
    "    if feature_column != change_type_column and feature_column != 'geometry':  # Skip the 'change_type' column itself and 'geometry'\n",
    "        feature_values = [group[feature_column].dropna() for _, group in grouped_data]\n",
    "        f_statistic, p_value = f_oneway(*feature_values)\n",
    "        f_values.append((feature_column, f_statistic, p_value))\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "f_values_df = pd.DataFrame(f_values, columns=['Feature', 'F-value', 'P-value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print or analyze the F-values DataFrame\n",
    "sorted_f_values_df= f_values_df.sort_values(by='F-value')\n",
    "sorted_f_values_df.to_csv(\"ANOVA.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To inspect\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid field type <class 'pandas._libs.tslibs.timedeltas.Timedelta'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/rick/Dropbox/disciplininhas/SG6/ML/machine-learning-cs/data/data_preprocessing.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rick/Dropbox/disciplininhas/SG6/ML/machine-learning-cs/data/data_preprocessing.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## Save output file\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rick/Dropbox/disciplininhas/SG6/ML/machine-learning-cs/data/data_preprocessing.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_df\u001b[39m.\u001b[39;49mto_file(OUTPUT_FILE) \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/geopandas/geodataframe.py:1246\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[0;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \n\u001b[1;32m   1157\u001b[0m \u001b[39mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \n\u001b[1;32m   1243\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgeopandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfile\u001b[39;00m \u001b[39mimport\u001b[39;00m _to_file\n\u001b[0;32m-> 1246\u001b[0m _to_file(\u001b[39mself\u001b[39;49m, filename, driver, schema, index, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/geopandas/io/file.py:633\u001b[0m, in \u001b[0;36m_to_file\u001b[0;34m(df, filename, driver, schema, index, mode, crs, engine, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m should be one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfiona\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 633\u001b[0m     _to_file_fiona(df, filename, driver, schema, crs, mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    634\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyogrio\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    635\u001b[0m     _to_file_pyogrio(df, filename, driver, schema, crs, mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/geopandas/io/file.py:664\u001b[0m, in \u001b[0;36m_to_file_fiona\u001b[0;34m(df, filename, driver, schema, crs, mode, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m     crs_wkt \u001b[39m=\u001b[39m crs\u001b[39m.\u001b[39mto_wkt(\u001b[39m\"\u001b[39m\u001b[39mWKT1_GDAL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    661\u001b[0m \u001b[39mwith\u001b[39;00m fiona\u001b[39m.\u001b[39mopen(\n\u001b[1;32m    662\u001b[0m     filename, mode\u001b[39m=\u001b[39mmode, driver\u001b[39m=\u001b[39mdriver, crs_wkt\u001b[39m=\u001b[39mcrs_wkt, schema\u001b[39m=\u001b[39mschema, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    663\u001b[0m ) \u001b[39mas\u001b[39;00m colxn:\n\u001b[0;32m--> 664\u001b[0m     colxn\u001b[39m.\u001b[39;49mwriterecords(df\u001b[39m.\u001b[39;49miterfeatures())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fiona/collection.py:558\u001b[0m, in \u001b[0;36mCollection.writerecords\u001b[0;34m(self, records)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcollection not open for writing\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 558\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mwriterecs(records, \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    559\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_len \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mget_length()\n\u001b[1;32m    560\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:1409\u001b[0m, in \u001b[0;36mfiona.ogrext.WritingSession.writerecs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:514\u001b[0m, in \u001b[0;36mfiona.ogrext.OGRFeatureBuilder.build\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid field type <class 'pandas._libs.tslibs.timedeltas.Timedelta'>"
     ]
    }
   ],
   "source": [
    "## Save output file\n",
    "train_df.to_file(OUTPUT_FILE) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
